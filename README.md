# ðŸš€ Desafio 01 - Engenharia de Dados

Este projeto implementa um **pipeline de dados automatizado** utilizando **Apache Airflow**, **Python**, **SQLAlchemy** e **Render (PostgreSQL hospedado)**.  
O objetivo Ã© realizar a **extraÃ§Ã£o, validaÃ§Ã£o, transformaÃ§Ã£o e carga** de dados de cotaÃ§Ã£o do **Bitcoin (BTC)** em relaÃ§Ã£o ao **DÃ³lar (USD)**, salvando-os em um banco de dados relacional.

---

## ðŸ“‚ Estrutura do Projeto

DESAFIO_01_ENGENHARIA/
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ pipeline.py # DAG principal do Airflow
â”‚ â””â”€â”€ .airflowignore
â”‚
â”œâ”€â”€ include/
â”‚ â”œâ”€â”€ controllers/
â”‚ â”‚ â”œâ”€â”€ controller.py # Camada de controle (extraÃ§Ã£o e orquestraÃ§Ã£o)
â”‚ â”‚ â””â”€â”€ init.py
â”‚ â”‚
â”‚ â”œâ”€â”€ database/
â”‚ â”‚ â”œâ”€â”€ db.py # ConfiguraÃ§Ã£o da conexÃ£o com PostgreSQL
â”‚ â”‚ â”œâ”€â”€ db_models.py # Modelos ORM com SQLAlchemy
â”‚ â”‚ â””â”€â”€ init.py
â”‚ â”‚
â”‚ â””â”€â”€ schemas/
â”‚ â”œâ”€â”€ schema.py # ValidaÃ§Ã£o de dados com Pydantic
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ plugins/ # Plugins customizados (caso necessÃ¡rios)
â”‚
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ dags/
â”‚ â””â”€â”€ test_dag_example.py # Teste bÃ¡sico de execuÃ§Ã£o da DAG
â”‚
â”œâ”€â”€ Dockerfile # ConfiguraÃ§Ã£o do ambiente Docker
â”œâ”€â”€ airflow_settings.yaml # DefiniÃ§Ãµes de conexÃµes e variÃ¡veis do Airflow
â”œâ”€â”€ .env # VariÃ¡veis de ambiente (credenciais e configs)
â”œâ”€â”€ .gitignore # Arquivos ignorados pelo Git
â”œâ”€â”€ .dockerignore
â””â”€â”€ .python-version # VersÃ£o utilizada no ambiente virtual


---

## ðŸ§  Fluxo do Pipeline

1. **ExtraÃ§Ã£o (Extract)**  
   A DAG coleta dados da cotaÃ§Ã£o do Bitcoin atravÃ©s de uma API pÃºblica.  
   Exemplo de endpoint:  
   ```bash
   https://api.coinbase.com/v2/prices/BTC-USD/spot
2. **ValidaÃ§Ã£o (Validate)**
    Os dados recebidos sÃ£o validados por modelos Pydantic definidos em schemas/schema.py, garantindo tipos corretos e presenÃ§a de campos obrigatÃ³rios.
3. **TransformaÃ§Ã£o (Transform)**
    Ajustes sÃ£o aplicados aos campos de data, valores e formataÃ§Ã£o numÃ©rica antes da carga.
4. **Carga (Load)**
    Os dados validados sÃ£o salvos no banco de dados PostgreSQL hospedado no Render.
    O SQLAlchemy gerencia a persistÃªncia atravÃ©s do modelo BitcoinTable.

## Modelo do Banco de Dados ##

Tabela: bitcoin

Campo	Tipo	DescriÃ§Ã£o
id	SERIAL PK	Identificador Ãºnico
amount	NUMERIC	Valor da cotaÃ§Ã£o
base	VARCHAR	Moeda base (BTC)
currency	VARCHAR	Moeda de conversÃ£o (USD)
timestamp	TIMESTAMP	Momento da coleta

Exemplo de dados:

id	amount	base	currency	timestamp
1	110.207,985	BTC	USD	2025-10-24 00:30:12.964
2	110.420,415	BTC	USD	2025-10-24 00:45:12.702
3	110.458,235	BTC	USD	2025-10-24 01

## ConfiguraÃ§Ã£o do Ambiente ##
1. Clone o repositÃ³rio
git clone https://github.com/seu-usuario/DESAFIO_01_ENGENHARIA.git
cd DESAFIO_01_ENGENHARIA

2. Crie o ambiente virtual
python -m venv .venv
source .venv/Scripts/activate   # Windows
# ou
source .venv/bin/activate       # Linux/Mac

3. Instale as dependÃªncias
pip install -r requirements.txt

4. Configure as variÃ¡veis de ambiente (.env)
DATABASE_URL=postgresql+psycopg2://usuario:senha@host:porta/nome_banco
API_URL=https://api.coinbase.com/v2/prices/BTC-USD/spot

5. Suba o ambiente do Airflow
astro dev start


Acesse o painel:
http://localhost:8080

UsuÃ¡rio padrÃ£o: admin | Senha: admin

## Deploy no Render ##

O banco PostgreSQL Ã© hospedado no Render
.
Durante a execuÃ§Ã£o, o pipeline envia as inserÃ§Ãµes diretamente para a instÃ¢ncia configurada.

## Autor ##
Nicolas Nagel
Contato: [nicolascnagel@gmail.com]
Foco: Engenharia de Dados | AutomaÃ§Ã£o de Pipelines | IntegraÃ§Ã£o de APIs# desafio_01_engenharia
